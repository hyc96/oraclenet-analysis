# OracleNet
Code, animations, and supplementary material for OracleNet 


[![OracleNet](https://img.youtube.com/vi/2KYesBrx2kk/0.jpg)](https://youtu.be/2KYesBrx2kk "OracleNet")

[![Baxter](https://img.youtube.com/vi/a440JJRSzy4/0.jpg)](https://www.youtube.com/watch?v=a440JJRSzy4)

[![OracleNet](https://img.youtube.com/vi/oXUeDx4AHYU/0.jpg)](https://youtu.be/oXUeDx4AHYU "OracleNet Baxter Right")

Performance trends with variable dataset and network sizes
----------------------------------------------------------

To analyze the learning capabilities of OracleNet, we performed experiments on environment 'Difficult 2' (refer to Fig. 5 in the paper) with variable dataset and network sizes. Success rates and path optimality (benchmarked against A*) are used to measure performance trends. For obvious reasons, it is not possible to compare all dataset sizes to all network sizes, therefore the trends presented here are meant to serve as an approximate guide to selecting reasonable datasets and network configurations. Note that all trends presented here do not involve the use of the repair and rewire modules, since the purpose is to (1) study the role of dataset and network sizes in generating successful paths, and (2) to show that with sufficient data and an appropriately chosen well-trained network, OracleNet is able to generate near-optimal feasible paths on its own and repair is needed only to handle the edge cases while rewire takes it closer to being absolutely optimal. Thus, the paths generated for the analysis presented here are directly generated by the network and do not involve any correction/processing. 

### Variable Dataset Sizes ###

![alt text](../master/Trends/trend_po_d.png?raw=true "Dataset Trends")


The network size is kept fixed here (refer to the network architecture described in Section IV.A) and the dataset size is incrementally increased to a maximum of 100,000 valid A* generated paths. It is to be expected that the network will predict paths more accurately when a larger training set is provided. Note that success rates reach greater than 90% with 20,000 training paths and continue on an upward trend till it reaches ~99% when 60,000 paths are considered for training. Path optimality for OracleNet climbs quickly to reach A*'s level of optimality and does not seem to be as dependent on dataset size as success rate (only the optimality statistics of successful paths are considered). 

From the graph, it can be inferred that selecting a dataset size between the two aforementioned values to get a good raw success rate while relying on repair/rewire to handle the remaining 5 % of the cases is the reasonable strategy to choose. Also, the environment chosen here has a large number of arbitrarily placed obstacles leading to a high degree of non-linearity in path shapes, hence a larger than average dataset may be required. 


### Variable Network Sizes ###

![alt text](../master/Trends/trend_po_n.png?raw=true "Network Trends")

The dataset size is kept fixed here at 100,000 valid paths while the network size (number of parameters, with each increment indicating an additional layer with 256 units) is kept variable. Note that the network configuration used in the paper and in the previous section has 2 million (2 M) parameters. It has already been established in the previous section that using 100,000 paths with 2 M parameters leads to >99% success rate, which is corroborated here as well. It is interesting to note the falling performance metrics when network size grows beyond a certain range. This can be attributed to the network having too many trainable weights as compared to training data which causes it to overfit quickly and performly poorly with unseen test sets. 
